<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Linluochen丶Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://linluochen.cn/"/>
  <updated>2020-06-09T06:48:26.797Z</updated>
  <id>http://linluochen.cn/</id>
  
  <author>
    <name>林洛尘</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Python 基础爬虫（二）Requests库</title>
    <link href="http://linluochen.cn/2020/06/04/python/requests/"/>
    <id>http://linluochen.cn/2020/06/04/python/requests/</id>
    <published>2020-06-04T08:46:39.000Z</published>
    <updated>2020-06-09T06:48:26.797Z</updated>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h2 id="什么是-Requests-库"><a href="#什么是-Requests-库" class="headerlink" title="什么是 Requests 库"></a>什么是 Requests 库</h2><p>&ensp;&ensp;&ensp;&ensp;Requests 是一常用的 HTTP 请求库，它使用 Python 语言编写，基于 urllib，采用 Apache2 Licensed 开源协议的 HTTP 库，可以方便地发送 HTTP 请求，以及方便地处理响应结果（用了 Requests 之后，你基本都不愿意用 urllib 了）<a id="more"></a></p><hr><h2 id="运行环境"><a href="#运行环境" class="headerlink" title="运行环境"></a>运行环境</h2><p>&ensp;&ensp;&ensp;&ensp;博主使用的是 IDE 系列的 PyCharm 一个很好用的神器（不是打广告！！是真的好用！！！）</p><h2 id="安装方式"><a href="#安装方式" class="headerlink" title="安装方式"></a>安装方式</h2><p>&ensp;&ensp;&ensp;&ensp;1.windows + R 输入 cmd 右键管理员运行，输入 pip insrall requests<br>&ensp;&ensp;&ensp;&ensp;2.使用 Anaconda 版本的朋友 在命令窗口输入 conda install requests<br>&ensp;&ensp;&ensp;&ensp;3.使用 PyCharm 进行安装 file-》default settings-》project interpreter-》搜索 requests-》install package-》ok<br><img src="https://img-blog.csdnimg.cn/20200604150959692.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xpbl9CbG9nXw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="使用方式"><a href="#使用方式" class="headerlink" title="使用方式"></a>使用方式</h2><p>&ensp;&ensp;&ensp;&ensp;打开我们的 PyCharm 工具，新建一个 Python 文件，在目录右键新建一个 Python 文件，然后输入文件名称，然后回车就行了<br><img src="https://img-blog.csdnimg.cn/20200604151418976.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xpbl9CbG9nXw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="先写一个最简单的爬虫（GET-请求）"><a href="#先写一个最简单的爬虫（GET-请求）" class="headerlink" title="先写一个最简单的爬虫（GET 请求）"></a>先写一个最简单的爬虫（GET 请求）</h3><p>&ensp;&ensp;&ensp;&ensp;我们的第一行代码首先是导入刚刚引入的 requests 库</p><pre><code class="bash">import requests</code></pre><p>&ensp;&ensp;&ensp;&ensp;输入想要访问的目标网址并且获取他的响应状态，直接输入 <code>requests.get(&#39;目标网址&#39;)</code> 默认返回的是响应状态和响应对象</p><pre><code class="bash">requests.get(<span class="string">'http://www.baidu.com'</span>)  <span class="comment"># 要访问的目标网址</span><span class="built_in">print</span>(requests.get(<span class="string">'http://www.baidu.com'</span>)) <span class="comment"># 输出目标网址的响应状态</span></code></pre><p>&ensp;&ensp;&ensp;&ensp;完整代码如下，这个 <code>if __name__ == &quot;__main__&quot;:</code> 相当于 Java 里边的 main 方法</p><pre><code class="bash">import requests<span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:    <span class="comment">#指定请求的url地址</span>    url = <span class="string">'http://www.baidu.com'</span>    <span class="comment">#使用requests模块的get函数根据指定的url发起一个get请求，get函数返回一个响应对象</span>    response = requests.get(url)    <span class="comment">#打印响应对象（结果：响应对象类型和响应状态码）</span>    <span class="built_in">print</span>(response)</code></pre><h4 id="属性介绍"><a href="#属性介绍" class="headerlink" title="属性介绍"></a>属性介绍</h4><p>&ensp;&ensp;&ensp;&ensp;使用 requests 模块向百度首页面发起一个 get 请求，获取响应对象</p><pre><code class="bash">import requests<span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:    <span class="comment">#指定请求的url</span>    url = <span class="string">'http://www.baidu.com'</span>    <span class="comment">#使用requests模块的get函数根据指定的url发起一个get请求，get函数返回一个响应对象</span>    response = requests.get(url)    <span class="comment">#获取请求的url</span>    <span class="built_in">print</span>(<span class="string">'请求的url:'</span>+response.url)    <span class="comment">#获取响应状态码</span>    <span class="built_in">print</span>(response.status_code)    <span class="comment">#获取响应内容的编码格式,可以通过该属性修改响应的编码格式，直接以赋值的形式就可以修改响应的编码方式，一般出现乱码是我们需要进行设置</span>    <span class="built_in">print</span>(<span class="string">'响应内容编码：'</span>+response.encoding)    <span class="comment">#获取响应对象的响应头信息：</span>    <span class="built_in">print</span>(response.headers)    <span class="comment">#获取字符串形式的响应内容，即是我们通过审查元素看到的HTML内容</span>    <span class="built_in">print</span>(response.text)    <span class="comment">#获取字节形式的响应内容，是bytes类型，一般我们请求图频、音频、视频需要用到字节流形式的响应内容</span>    <span class="built_in">print</span>(response.content)</code></pre><h4 id="设置响应头"><a href="#设置响应头" class="headerlink" title="设置响应头"></a>设置响应头</h4><p>&ensp;&ensp;&ensp;&ensp;在请求头中有一个参数为User-Agent，<spen style="color:red">表示含义为请求载体的身份标识</spen>。通过浏览器发起的请求，请求载体为浏览器，则该请求的<spen style="color:red">User-Agent为浏览器的身份标识</spen>，使用爬虫程序发起的请求，则该请求的载体为爬虫程序，则该请求的User-Agent为爬虫程序的身份标识。<spen style="color:red">爬虫程序想要尽可能的模拟浏览器发起的请求，则必须将User-Agent修改成浏览器的身份标识</spen>。</p><p><spen style="color:red"><strong>注意：User-Agent的定制其实是一种反反爬虫的初级技术手段。所以在编写爬虫程序时，必须对User-Agent进行手动定制。User-Agent的值可以通过抓包工具从浏览器请求的请求头中获取。</strong></spen></p><pre><code class="bash">import requests<span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:    <span class="comment">#指定请求的url</span>    url = <span class="string">'http://www.baidu.com'</span>    <span class="comment">#定制请求头信息，相关的头信息必须封装在字典结构中</span>    headers = {        <span class="comment">#定制请求头中的User-Agent参数，当然也可以定制请求头中其他的参数</span>        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'</span>,    }    <span class="comment">#使用requests模块的get函数根据指定的url发起一个get请求，get函数返回一个响应对象</span>    <span class="comment">#参数1：发起请求指定的url</span>    <span class="comment">#参数2：手动定制的请求头信息</span>    response = requests.get(url=url,headers=headers)    <span class="comment">#打印响应的状态码</span>    <span class="built_in">print</span>(response.status_code)</code></pre><h4 id="携带参数的-GET-请求"><a href="#携带参数的-GET-请求" class="headerlink" title="携带参数的 GET 请求"></a>携带参数的 GET 请求</h4><p><spen style="color:red"><strong>注意：url有一个显著的特性。url必须是使用ASCII进行编码的字符方可生效。但是在requests模块中，即使url中存在非ASCII字符，那么requests会对其自动进行转化。</strong></spen></p><pre><code class="bash">import requests<span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:    <span class="comment">#指定请求的url：可以将get请求携带的参数拼接到url域名后面，但是不建议大家这么做，一般我们将携带的参数以键值对的形式封装到字典中，操作见下方：</span>    <span class="comment">#url = 'http://www.baidu.com/s?ie=utf-8&amp;wd=周杰伦'</span>    <span class="comment">#建议做法：指定请求网页的域名</span>    url = <span class="string">'https://www.baidu.com/s'</span>    <span class="comment">#将请求携带的参数以键值对的形式封装到字典中，准备待用</span>    param = {        <span class="string">'ie'</span> : <span class="string">'utf-8'</span>,        <span class="string">'wd'</span> : <span class="string">'星星'</span>    }    <span class="comment">#定制请求头信息，相关的头信息必须封装在字典结构中</span>    headers = {        <span class="comment">#定制请求头中的User-Agent参数，当然也可以定制请求头中其他的参数</span>        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'</span>,    }    <span class="comment">#使用requests模块的get函数根据指定的url发起一个get请求，get函数返回一个响应对象，get中传入的三个参数如下：</span>    <span class="comment">#参数1：发起请求指定的url</span>    <span class="comment">#参数2：手动定制的请求头信息</span>    <span class="comment">#参数3：指定请求携带的参数</span>    response = requests.get(url=url,headers=headers,params=param)    <span class="comment">#设置响应内容的编码格式（如果写入文件内容出现乱码的话）</span>    response.encoding = <span class="string">'utf-8'</span>    <span class="comment">#获取响应的网页内容，存储的文件名我们也可以根据用户输入，存成一个动态文件名</span>    page_data = response.text    with open(<span class="string">'./星星.html'</span>,<span class="string">'w'</span>) as fp:        fp.write(page_data)</code></pre><h3 id="写一个最简单的爬虫（POST-请求）"><a href="#写一个最简单的爬虫（POST-请求）" class="headerlink" title="写一个最简单的爬虫（POST 请求）"></a>写一个最简单的爬虫（POST 请求）</h3><h4 id="携带参数的-POST-请求"><a href="#携带参数的-POST-请求" class="headerlink" title="携带参数的 POST 请求"></a>携带参数的 POST 请求</h4><p><spen style="color:red"><strong>注意：这个地方有一个小坑，使用 GET 方法带参数请求时，是 params=参数字典，而不是 data，data 是POST 方法的参数</strong></spen></p><pre><code class="bash">import requests<span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:    <span class="comment">#指定post请求的url</span>    url = <span class="string">'https://fanyi.baidu.com/sug'</span>    <span class="comment">#定制请求头信息，相关的头信息必须封装在字典结构中</span>    headers = {        <span class="comment">#定制请求头中的User-Agent参数，将爬虫伪装的更像浏览器，当然也可以定制请求头中其他的参数</span>        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'</span>,    }    <span class="comment">#定制post请求携带的参数,可以使用抓包工具看需要传哪些参数，如Fiddler抓包工具</span>    data = {        <span class="string">'kw'</span> : <span class="string">'dog'</span>    }    <span class="comment">#使用requests模块的post函数根据指定的url发起一个post请求，post函数返回一个响应对象</span>    <span class="comment">#参数1：发起请求指定的url</span>    <span class="comment">#参数2：手动定制的请求头信息</span>    <span class="comment">#参数3：指定请求携带的参数</span>    response = requests.post(url=url,headers=headers,data=data)    <span class="comment">#获取响应内容：响应内容为json串</span>    <span class="built_in">print</span>(response.text)</code></pre><h3 id="其他请求"><a href="#其他请求" class="headerlink" title="其他请求"></a>其他请求</h3><p>&ensp;&ensp;&ensp;&ensp;Requests 的功能那么强大当然不仅仅限于 GET 和 POST 请求啦，其他一些请求例如 put 请求、delete 请求、head 请求、option 请求等其实都是类似的，但是平时用的不多，就不仔细介绍了，有用到的可以去看官网文档哦。</p><h2 id="后话"><a href="#后话" class="headerlink" title="后话"></a>后话</h2><p>下一张的内容就是 BeautifulSoup 库，我们的解析库！<br>本文借鉴于：<a href="https://www.cnblogs.com/sui776265233/p/9703712.html" target="_blank" rel="noopener">Requests 库介绍</a>和<a href="https://www.cnblogs.com/Albert-Lee/p/6230337.html" target="_blank" rel="noopener">基础入门</a></p>]]></content>
    
    <summary type="html">
    
      &lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;&gt;

&lt;h2 id=&quot;什么是-Requests-库&quot;&gt;&lt;a href=&quot;#什么是-Requests-库&quot; class=&quot;headerlink&quot; title=&quot;什么是 Requests 库&quot;&gt;&lt;/a&gt;什么是 Requests 库&lt;/h2&gt;&lt;p&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;Requests 是一常用的 HTTP 请求库，它使用 Python 语言编写，基于 urllib，采用 Apache2 Licensed 开源协议的 HTTP 库，可以方便地发送 HTTP 请求，以及方便地处理响应结果（用了 Requests 之后，你基本都不愿意用 urllib 了）
    
    </summary>
    
      <category term="Python" scheme="http://linluochen.cn/categories/Python/"/>
    
    
      <category term="Python" scheme="http://linluochen.cn/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python 基础爬虫（一）介绍篇</title>
    <link href="http://linluochen.cn/2020/06/04/python/introduce/"/>
    <id>http://linluochen.cn/2020/06/04/python/introduce/</id>
    <published>2020-06-04T02:46:39.000Z</published>
    <updated>2020-06-04T07:11:09.140Z</updated>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>&ensp;&ensp;&ensp;&ensp;其实说实话呢，博主也是正在学习 Python 这门语言（主要还是学习网络爬虫这一块），博主主职还是 Java 开发，这次学习也是直接略过了基础这一块直接上手的爬虫，可能会有讲不到或者有不对的地方，请多多包含，欢迎大佬们在评论区给一些建议！！感谢！！下面的介绍主要还是关于爬虫相关的内容<a id="more"></a></p><hr><h2 id="什么是爬虫？"><a href="#什么是爬虫？" class="headerlink" title="什么是爬虫？"></a>什么是爬虫？</h2><p>&ensp;&ensp;&ensp;&ensp;爬虫全称：网络爬虫（又称为网页蜘蛛，网络机器人，在 FOAF 社区中间，更经常的称为网页追逐者），是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本。另外一些不常使用的名字还有蚂蚁、自动索引、模拟程序或者蠕虫。简单来讲爬虫就相当于是一个探测器，它最常用的操作就是模拟人的行为去各个网站溜达，点点按钮，查查数据，或者把看到的信息背回来。就像一只虫子在一幢楼里不知疲倦地爬来爬去。</p><h2 id="爬虫最重要的三个特点！"><a href="#爬虫最重要的三个特点！" class="headerlink" title="爬虫最重要的三个特点！"></a>爬虫最重要的三个特点！</h2><p>&ensp;&ensp;&ensp;&ensp;<strong>1.抓取数据：</strong>相当于你打开百度搜索出来的东西，其实都是通过爬虫抓取过来的。<br>&ensp;&ensp;&ensp;&ensp;<strong>2.分析数据：</strong>相当于根据你输入的条件，筛选出来你想要的信息内容。<br>&ensp;&ensp;&ensp;&ensp;<strong>3.存储数据：</strong>相当于把你想要的信息，存放到你的数据库里，或者文本里。</p><h2 id="爬虫原理"><a href="#爬虫原理" class="headerlink" title="爬虫原理"></a>爬虫原理</h2><p>&ensp;&ensp;&ensp;&ensp;网络连接像是在自助饮料售货机上购买饮料一样：购买者只需选择所需饮料，投入硬币（或纸币），自助饮料售货机就会弹出相应的商品。<br><img src="https://img2018.cnblogs.com/blog/1551659/201812/1551659-20181201123834910-1933281612.png" alt><br>&ensp;&ensp;&ensp;&ensp;了解网络连接的基本原理后，爬虫原理就很好理解了。网络连接需要电脑一次 Requests 请求和服务器端的 Response 回应。爬虫也是需要这两件事：<br>&ensp;&ensp;&ensp;&ensp;（1）模拟电脑对服务器发起 Requests 请求。<br>&ensp;&ensp;&ensp;&ensp;（2）接收服务器端的 Response 的内容并解析提取所需信息。<br><img src="https://img2018.cnblogs.com/blog/1551659/201812/1551659-20181201124011394-1587463776.png" alt></p><h2 id="网页构造"><a href="#网页构造" class="headerlink" title="网页构造"></a>网页构造</h2><p>&ensp;&ensp;&ensp;&ensp;打开任意浏览器，然后随便找到一个网页，例如 CSDN 右键点击查看网页源代码，可以看到一个 HTML 的网页，我们的爬虫其实就是获取的 HTML 里边的信息<br><img src="https://img-blog.csdnimg.cn/2020060413500510.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NTM3NTQ2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>&ensp;&ensp;&ensp;&ensp;通过这个图，我们可以看到网页的”真实面目”,上半部分是我们引入的一些 Js 文件，下半部分则是一些网页中的内容，浏览器存在的作用就相当于一个翻译官一样，把我们的写的内容翻译成用户使用的网页界面</p><h2 id="学习爬虫的必备知识"><a href="#学习爬虫的必备知识" class="headerlink" title="学习爬虫的必备知识"></a>学习爬虫的必备知识</h2><ul><li>HTML ： 这个能够帮助你了解网页的结构，内容等。<a href="https://www.w3school.com.cn/html/index.asp" target="_blank" rel="noopener">W3School的教程</a></li><li>Python ： 如果有编程基础的小伙伴儿，推荐看一个<a href="https://www.liaoxuefeng.com/wiki/1016959663602400" target="_blank" rel="noopener">廖雪峰的Python教程</a>就够了，没有编程基础的小伙伴，推荐看看视频教程，或者可以看看<a href="https://www.zhihu.com/question/29138020" target="_blank" rel="noopener">知乎-如何系统的自学Python</a></li><li>TCP/IP协议，HTTP协议 ：这些知识能够让你了解在网络请求和网络传输上的基本原理，了解就行，能够帮助今后写爬虫的时候理解爬虫的逻辑</li></ul><hr><h2 id="后话"><a href="#后话" class="headerlink" title="后话"></a>后话</h2><p>本文借鉴于：<a href="https://www.cnblogs.com/Albert-Lee/p/6226699.html" target="_blank" rel="noopener">阿里波特-Python 爬虫</a> 和 <a href="https://zh.wikipedia.org/wiki/%E7%B6%B2%E8%B7%AF%E7%88%AC%E8%9F%B2" target="_blank" rel="noopener">维基百科</a>、<a href="https://www.cnblogs.com/wuxingqueshui/p/10049062.html" target="_blank" rel="noopener">_tu-爬虫原理和网页构造</a></p>]]></content>
    
    <summary type="html">
    
      &lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;&gt;

&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;&amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;其实说实话呢，博主也是正在学习 Python 这门语言（主要还是学习网络爬虫这一块），博主主职还是 Java 开发，这次学习也是直接略过了基础这一块直接上手的爬虫，可能会有讲不到或者有不对的地方，请多多包含，欢迎大佬们在评论区给一些建议！！感谢！！下面的介绍主要还是关于爬虫相关的内容
    
    </summary>
    
      <category term="Python" scheme="http://linluochen.cn/categories/Python/"/>
    
    
      <category term="Python" scheme="http://linluochen.cn/tags/Python/"/>
    
  </entry>
  
</feed>
